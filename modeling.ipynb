{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import metrics\n",
    "\n",
    "import mlr_utils\n",
    "import ForwardStepCandidates_AKL as fsc_AKL\n",
    "import loo_q2 as loo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using Copilot to understand code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## separate files for exp data and comp data\n",
    "\n",
    "comp_file = \"Phosphine_library_DFT_props_191120_copy\" \n",
    "comp_sheet = \"selprops_use_2_bowls\" \n",
    "num_par = 182 \n",
    "par_start_col = 1   # 0-indexed\n",
    "comp_num_samples = 1359 \n",
    "y_label_col_comp = 0  # 0-indexed\n",
    "\n",
    "exp_file = \"exp_bowls\" \n",
    "exp_sheet = \"Sheet1\"\n",
    "exp_num_samples = 10 \n",
    "response_col = 9  # 0-indexed\n",
    "y_label_col_exp = 0  # 0-indexed\n",
    "\n",
    "compinp = pd.read_excel(comp_file+\".xlsx\",comp_sheet,header=0,index_col=y_label_col_comp,nrows=comp_num_samples+1,usecols=list(range(0,(num_par+par_start_col))))\n",
    "compinp.index = compinp.index.map(str)\n",
    "expinp = pd.read_excel(exp_file+\".xlsx\",exp_sheet,header=4,index_col=y_label_col_exp,nrows=exp_num_samples,usecols=list(range(0,response_col+1)))\n",
    "expinp.index = [i.zfill(4) for i in expinp.index.map(str)]\n",
    "\n",
    "xlabelrow = True\n",
    "verbose = True\n",
    "\n",
    "X_names = list(compinp.iloc[0,par_start_col-1:num_par+par_start_col-1])\n",
    "X_labels = list(compinp.columns)[par_start_col-1:num_par+par_start_col-1]\n",
    "compinp.drop(index=compinp.index[0],inplace=True)\n",
    "X_all = np.asarray(compinp[X_labels],dtype=np.float)\n",
    "y_labels_comp = np.asarray(list(compinp.index),dtype=str)\n",
    "compnan = np.isnan(X_all).any(axis=1)\n",
    "y_labels_comp,X_all = y_labels_comp[~compnan],X_all[~compnan]\n",
    "\n",
    "X_labelname = [\" \".join(i) for i in zip(X_labels,X_names)] \n",
    "X_labelname_dict = dict(zip(X_labels,X_names))\n",
    "\n",
    "resp_label = list(expinp.columns)[response_col-1]\n",
    "y = np.asarray(expinp.iloc[:,response_col-1],dtype=np.float)\n",
    "y_labels_exp = np.asarray(list(expinp.index),dtype=str)\n",
    "\n",
    "mask_y = y.nonzero()[0]\n",
    "mask_y = ~np.isnan(y)\n",
    "mask_X = np.array([True if i in y_labels_comp else False for i in y_labels_exp])\n",
    "mask = mask_y&mask_X\n",
    "print(\"n_samples before removing empty cells: {}\".format(len(y)))\n",
    "print(\"Removing {} samples.\".format(len(y)-sum(mask)))\n",
    "y = y[np.array(mask)]\n",
    "y_labels = y_labels_exp[np.array(mask)]\n",
    "\n",
    "X = np.asarray(compinp.loc[y_labels],dtype=np.float)\n",
    "\n",
    "if verbose:\n",
    "    print(\"Shape X (all): {}\".format(X_all.shape))\n",
    "    print(\"Shape X (exp): {}\".format(X.shape))\n",
    "    print(\"Shape y (exp): {}\".format(y.shape)) \n",
    "    print(\"Shape labels (exp): {}\".format(y_labels.shape)) \n",
    "    print(\"First X (exp) cell: {}\".format(X[0,0]))\n",
    "    print(\"Last X (exp) cell:  {}\".format(X[-1,-1]))\n",
    "    print(\"First y: {}\".format(y[0]))\n",
    "    print(\"Last y:  {}\".format(y[-1]))\n",
    "    print(\"Last label exp: {}\".format(y_labels[-1]))\n",
    "    print(\"Last label comp: {}\".format(y_labels_comp[-3:]))\n",
    "    #print(inp.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Actually read in data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameter file variables\n",
    "parameters_file = \"example_dataset\" \n",
    "parameters_sheet = \"Sheet1\" \n",
    "num_par = 20\n",
    "parameters_start_col = 2   # 0-indexed\n",
    "parameters_num_samples = 100 \n",
    "parameters_y_label_col = 0  # 0-indexed\n",
    "parameters_header_rows = 0\n",
    "\n",
    "# Response file variables\n",
    "response_file = \"example_dataset\"\n",
    "response_sheet = \"Sheet1\"\n",
    "response_num_samples = 100 \n",
    "response_col = 1 # 0-indexed\n",
    "response_y_label_col = 0  # 0-indexed\n",
    "response_header_rows = 1\n",
    "\n",
    "# Actually start reading stuff into dataframes\n",
    "parameters_df = pd.read_excel(\"./InputData/\" + parameters_file + \".xlsx\",\n",
    "                              parameters_sheet,\n",
    "                              header = parameters_header_rows,\n",
    "                              index_col = parameters_y_label_col,\n",
    "                              nrows = parameters_num_samples + 1,\n",
    "                              #usecols = list(range(0, (num_par + parameters_start_col)))\n",
    "                              )\n",
    "response_df = pd.read_excel(\"./InputData/\" + response_file + \".xlsx\",\n",
    "                            response_sheet,\n",
    "                            header = response_header_rows,\n",
    "                            index_col = response_y_label_col,\n",
    "                            nrows = response_num_samples,\n",
    "                            usecols = list(range(0, response_col + 1))\n",
    "                            )\n",
    "\n",
    "# Drop any columns before parameters_start_col that are not the index column\n",
    "parameters_columns_to_keep = [col for col in range(0, len(parameters_df.columns)) if col >= parameters_start_col-1]\n",
    "parameters_df = parameters_df.iloc[:,parameters_columns_to_keep]\n",
    "\n",
    "# Combine the two dataframes into the master dataframe\n",
    "response_df.drop(response_df.columns[0:response_col-1], axis = 'columns', inplace = True)\n",
    "data_df = response_df.merge(parameters_df, left_index = True, right_index = True, how='inner')\n",
    "data_df.columns.values[0] = 'response' # Converts the output column name from whatever it is on the spreadsheet\n",
    "data_df.dropna(inplace = True) # This trims the dataframe down to only the rows relevant to this dataset\n",
    "\n",
    "# Creates a dictionary to convert x# labels to full parameter names\n",
    "x_names = list(parameters_df.iloc[0, :num_par])\n",
    "x_labels = list(parameters_df.columns)[:num_par]\n",
    "x_labelname_dict = dict(zip(x_labels, x_names))\n",
    "\n",
    "print(\"Parameter file shape: {}\".format(parameters_df.shape))\n",
    "print(\"Final parameter quantity: {}\".format(len(x_labels)))\n",
    "print(\"Final experiment quantity: {}\".format(data_df.shape[0]))\n",
    "print(\"First parameter cell: {}\".format(data_df[x_labels[0]].iloc[0]))\n",
    "print(\"Last parameter cell:  {}\".format(data_df[x_labels[-1]].iloc[-1]))\n",
    "print(\"First y: {}\".format(data_df.iloc[0,0]))\n",
    "print(\"Last y:  {}\".format(data_df.iloc[-1,0]))\n",
    "print(\"First reaction label: {}\".format(data_df.index[0]))\n",
    "print(\"Last reaction label:  {}\".format(data_df.index[-1]))\n",
    "\n",
    "display(data_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Start modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "split = \"y_equidist\"\n",
    "test_ratio = 0.3 \n",
    "\n",
    "# New train_test_splits set up returns the data_df index labels for the relevant points\n",
    "training_set, test_set = mlr_utils.train_test_splits(data_df, split, test_ratio)\n",
    "\n",
    "# Scale the parameters then puts them into scaled_data_df\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(data_df.loc[training_set, :])\n",
    "scaled_data = scaler.transform(data_df)\n",
    "scaled_data_df = pd.DataFrame(scaled_data, index = data_df.index, columns = data_df.columns)\n",
    "scaled_data_df[['response']] = data_df[['response']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_fit(y_train,\n",
    "             y_pred_train,\n",
    "             y_test,\n",
    "             y_pred_test,\n",
    "             y_extra_measured=[],\n",
    "             y_extra_predicted=[],\n",
    "             leg=True,\n",
    "             sav=False,\n",
    "             label=\"y\",\n",
    "             loo_pred=[],\n",
    "             plot_lims=[0,0]):\n",
    "    \n",
    "    y_orig_min = np.min(np.hstack((y_train,y_test)))\n",
    "    y_pred_min = np.min(np.hstack((y_pred_train,y_pred_test)))\n",
    "    y_orig_max = np.max(np.hstack((y_train,y_test)))\n",
    "    y_pred_max = np.max(np.hstack((y_pred_train,y_pred_test)))\n",
    "    delta_x = 0.04 * (y_orig_max-y_orig_min)\n",
    "    delta_y = 0.04 * (y_pred_max-y_pred_min)\n",
    "           \n",
    "    yy_fit = np.polyfit(y_train,y_pred_train,deg=1)\n",
    "    yy_fit_line = yy_fit[1]+yy_fit[0]*y_train\n",
    "    \n",
    "    plt.figure(figsize=(5,5))\n",
    "    plt.xlim([y_orig_min-delta_x,y_orig_max+delta_x])\n",
    "    plt.ylim([y_pred_min-delta_y,y_pred_max+delta_y])\n",
    "\n",
    "    if len(loo_pred) != 0:\n",
    "        plt.scatter(y_train,loo_train,label=\"LOO\",color=\"black\",marker=\".\",facecolor='none',s=200)\n",
    "    plt.scatter(y_train,y_pred_train,label=\"training\",color=\"black\",marker=\".\",s=200)\n",
    "    plt.scatter(y_test,y_pred_test,label=\"test\",color='red',marker=\".\",linewidth=3, s=200)\n",
    "    if len(y_extra_measured)>0:\n",
    "        plt.scatter(y_extra_measured,y_extra_predicted,label=\"validation\",color='green',marker=\".\",linewidth=3, s=200)\n",
    "\n",
    "    plt.plot(y_train,yy_fit_line,color=\"darkgrey\",linestyle='--',dashes=[5,15])\n",
    "    if leg:\n",
    "        plt.legend(loc='lower right', fontsize=10)\n",
    "    plt.xlabel(label+\" measured\",fontsize=18, fontweight='bold')\n",
    "    plt.ylabel(label+\" predicted\",fontsize=18, fontweight='bold')\n",
    "    \n",
    "    plt.xticks(fontsize=14)\n",
    "    plt.yticks(fontsize=14)\n",
    "    \n",
    "    num_ticks = 5\n",
    "    if(plot_lims == [0,0]):\n",
    "        ax_start = 0\n",
    "        ax_end = max(max(y_train), max(y_test)) * 1.1\n",
    "    else:\n",
    "        ax_start = plot_lims[0]\n",
    "        ax_end = plot_lims[1]\n",
    "        \n",
    "    ticks = np.linspace(ax_start, ax_end, num_ticks)\n",
    "    ticks = np.round(ticks, decimals=1)\n",
    "\n",
    "    plt.gca().set_xticks(ticks)\n",
    "    plt.gca().set_yticks(ticks)\n",
    "    plt.gca().set_aspect('equal')\n",
    "    \n",
    "    plt.gca().spines['right'].set_color('none')\n",
    "    plt.gca().spines['top'].set_color('none')\n",
    "\n",
    "    plt.gcf().tight_layout()\n",
    "    \n",
    "    if not sav:\n",
    "        plt.show()  \n",
    "    else:\n",
    "        plt.savefig(sav, dpi=300, bbox_inches='tight', transparent=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Forward stepwise selection keeping a set of candidates at each step\n",
    "\n",
    "n_steps = 3\n",
    "n_candidates = 30\n",
    "collin_criteria = 0.5 # this is R2\n",
    "# skipfeatures = [] #[\"x4\",\"x3\"]\n",
    "\n",
    "%notebook inline\n",
    "plt.ioff()\n",
    "\n",
    "modeling_data_df = scaled_data_df.drop(axis = 'columns', labels = 'y_class')\n",
    "modeling_data_df = modeling_data_df.loc[training_set, :]\n",
    "\n",
    "modeling_data_df = scaled_data_df.loc[training_set, :]\n",
    "\n",
    "# I think this is the function that actually does the MLR\n",
    "results,models,scores,sortedmodels,candidates = fsc_AKL.ForwardStep_py(modeling_data_df,'response',\n",
    "                    n_steps=n_steps,n_candidates=n_candidates,collin_criteria=collin_criteria)\n",
    "\n",
    "# Identify the best model from the ForwardStep algorithm\n",
    "selected_model_terms = results.loc[0, \"Model\"] # Store a tuple of 'xIDs' for the best model\n",
    "selected_model = models[selected_model_terms].model # Store the LinearRegression object for that model\n",
    "\n",
    "# Break up the train/test data into smaller dataframes for easy reference\n",
    "x_train = scaled_data_df.loc[training_set, selected_model_terms] # Dataframe containing just the parameters used in this model for the ligands used in the training set\n",
    "x_test = scaled_data_df.loc[test_set, selected_model_terms] # Dataframe containing just the parameters used in this model for the ligands used in the test set\n",
    "y_train = scaled_data_df.loc[training_set, 'response']\n",
    "y_test = scaled_data_df.loc[test_set, 'response']\n",
    "\n",
    "# Predict the train and test sets with the model\n",
    "y_predictions_train = selected_model.predict(x_train)\n",
    "y_predictions_test =  selected_model.predict(x_test)\n",
    "\n",
    "# Calculate q2 and k-fold for the model\n",
    "q2, loo_train = loo.q2_df(x_train,y_train)\n",
    "kfoldscores = mlr_utils.repeated_k_fold(np.asarray(x_train), np.asarray(y_train), k=5, n=100)\n",
    "\n",
    "# Print a bunch of stats about the model\n",
    "print(f\"\\nSplit method: {split}\")\n",
    "print(f\"Test ratio: {test_ratio}\")\n",
    "\n",
    "print(f'\\nParameters:\\n{selected_model.intercept_:10.4f} +')\n",
    "for i, parameter in enumerate(selected_model_terms):\n",
    "    print(f'{selected_model.coef_[i]:10.4f} * {parameter} {x_labelname_dict[parameter]}')\n",
    "\n",
    "print(f\"\\nTraining R2  = {selected_model.score(x_train, y_train):.3f}\")\n",
    "print(f'Training Q2  = {q2:.3f}')\n",
    "print(f\"Training MAE = {metrics.mean_absolute_error(y_train,y_predictions_train):.3f}\")\n",
    "print(\"Training K-fold R2 = {:.3f} (+/- {:.3f})\".format(kfoldscores.mean(), kfoldscores.std() ** 2))\n",
    "\n",
    "print(f\"\\nTest R2      = {mlr_utils.r2_val(y_test,y_predictions_test,y_train):.3f}\")\n",
    "print(f'Test MAE     = {metrics.mean_absolute_error(y_test,y_predictions_test):.3f}')\n",
    "    \n",
    "# Plot the model\n",
    "plot_fit(y_train, y_predictions_train, y_test, y_predictions_test, leg=False, sav=False, label=\"Yield (%)\", loo_pred=loo_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Copilot-assisted implementation of Ridge Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "modeling",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
